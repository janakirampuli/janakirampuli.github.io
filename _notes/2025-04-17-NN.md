---
layout: notes
title: "Neural Networks"
tags: [ML, AI]
date: 2025-04-17
---

## What are Neural Networks?

Neural networks are computational models designed to recognise patterns and relationships in data through processes that mimic the way the human brain operates. Just as our brains consist of interconnected neurons that process and transmit information, artificial neural networks (ANNs) are composed of artificial neurons organised in layers that work together to learn from data and make predictions.

To understand this, let's draw parallels between neural networks and their biological counterparts.  In the human brain, neurons communicate through electrical signals transmitted via connections called synapses. A typical brain contains approximately 100 billion neurons, each connected to thousands of others. When a neuron receives sufficient input signals from its dendrites, it "fires," sending an electrical impulse along its axon to other neurons.

Artificial neural networks simplify this complex biological process. While they don't replicate all aspects of brain function (such as the creation or destruction of connections between neurons), they capture the essential learning mechanism that makes our brains so adaptable

---

## Layers of a neural network

Neural networks consist of three primary types of layers:

1. **Input Layer**: This is where data enters the network. Each neuron corresponds to a feature in the input dataset.
2. **Hidden Layers**: These intermediate layers process information received from the previous layer. The "deep" in deep learning refers to networks with multiple hidden layers, allowing them to learn increasingly complex patterns and abstractions.
3. **Output Layer**: This final layer produces the network's prediction or decision. Its structure depends on the task - for example, a single neuron for binary classification or multiple neurons for multi-class problems.

## **Neurons: The Building Blocks**

Neurons, also called nodes, are the fundamental units of neural networks. Each artificial neuron performs three key operations:

1. **Weighted Sum**: Multiplies each input by its corresponding weight and sums them together with a bias term.
2. **Activation**: Passes the weighted sum through an activation function that introduces non-linearity.
3. **Output**: Produces a signal that becomes input for neurons in the next layer.

Mathematically, this process can be represented as:

$$ o = f(\sum_{i=1}^{n} w_i x_i + b) $$

Where:

- $o$ is the output
- $f$ is the activation function
- $w_i$ are the weights
- $x_i$ are the inputs
- $b$ is the bias term

## **Activation Functions**

Activation functions are crucial as they introduce non-linearity into the network, enabling it to learn complex patterns. Common activation functions include:

1. **Sigmoid**: Squashes values between 0 and 1, often used for binary classification problems.
2. **ReLU (Rectified Linear Unit)**: Outputs the input for positive values and zero for negative values, helping prevent the vanishing gradient problem in deep networks.
3. **Tanh (Hyperbolic Tangent)**: This is similar to sigmoid but outputs values between -1 and 1.
4. **Softmax**: Commonly used in the output layer for multi-class classification, converting outputs into probability distributions.

## **Weights and Biases**

Weights determine the strength of connections between neurons, while biases allow neurons to make predictions even when inputs are zero. During training, these parameters are continuously adjusted to minimize the difference between predicted and actual outputs.

---

## **How Neural Networks Work**
<p style="text-align: center;">
    <img src="/assets/images/1_nn.png" alt="Deep Neural Network" width="60%" class="img-center">
</p>

## **Forward Propagation**

Forward propagation is the process of passing input data through the network to generate an output. For example, in a simple network with two inputs, a hidden layer with two neurons, and one output neuron, the process works as follows:

1. Input values are fed into the input layer
2. Each input is multiplied by its corresponding weight
3. The weighted inputs are summed with the bias
4. This sum passes through an activation function
5. The output becomes input for the next layer
6. This process continues until reaching the output layer

## **Backpropagation and Training**

Neural networks learn through a process called backpropagation, which involves:

1. **Loss Calculation**: After forward propagation, the network calculates the error (or loss) between its predictions and the actual values. Common loss functions include Mean Squared Error (MSE) for regression and Cross-Entropy for classification.
2. **Gradient Computation**: The network computes gradients that indicate how much each weight and bias should change to reduce the error.
3. **Weight Update**: Weights and biases are adjusted using an optimization algorithm, such as gradient descent, which iteratively moves in the direction that minimizes the loss function.

This process repeats for many iterations (epochs) until the network achieves satisfactory performance. As training progresses, the network gradually learns to recognize patterns in the data and make increasingly accurate predictions.

---

## Forward Propagation: The Prediction Engine

Forward propagation transforms input data into predictions through sequential layer computations. For a network with $ L $ layers:

### 1. **Weighted Sum Calculation (Pre-activation)**

For layer $l$, the pre-activation $ \mathbf{Z}^{(l)} $ is computed as:

$$
\mathbf{Z}^{(l)} = \mathbf{A}^{(l-1)} \mathbf{W}^{(l)} + \mathbf{b}^{(l)}
$$

- $ \mathbf{A}^{(l-1)} $: Outputs from previous layer (input: $ \mathbf{A}^{(0)} = \mathbf{X} $)
- $ \mathbf{W}^{(l)} $: Weight matrix for layer $ l $
- $ \mathbf{b}^{(l)} $: Bias vector for layer $ l $


### 2. **Activation Function Application**

The output $ \mathbf{A}^{(l)} $ is generated by applying a non-linear activation function $ g $:

$$
\mathbf{A}^{(l)} = g(\mathbf{Z}^{(l)})
$$

Common activations:

- **ReLU**: $ g(z) = \max(0, z) $
- **Sigmoid**: $ g(z) = \frac{1}{1 + e^{-z}} $
- **Softmax** (output layer for classification): $ g(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}} $


### 3. **Final Output**

For regression, the output layer uses linear activation. For classification, softmax or sigmoid is used:

$$
\hat{\mathbf{y}} = \mathbf{A}^{(L)}
$$

---

## Backpropagation: The Learning Mechanism

Backpropagation computes gradients of the loss with respect to weights using the **chain rule**, enabling efficient weight updates.

### 1. **Loss Function Calculation**

Common loss functions:

- **Mean Squared Error (MSE)** for regression:

$$
L = \frac{1}{N} \sum_{i=1}^N (\hat{y}_i - y_i)^2
$$
- **Cross-Entropy** for classification:

$$
L = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log \hat{y}_i + (1 - y_i) \log(1 - \hat{y}_i) \right]
$$


### 2. **Gradient Computation**

Output Layer Gradient:

$$
\boldsymbol{\delta}^{(L)} = \nabla_{\mathbf{A}^{(L)}} L \odot g'(\mathbf{Z}^{(L)})
$$

- For MSE: $ \nabla_{\mathbf{A}^{(L)}} L = \hat{\mathbf{y}} - \mathbf{y} $
- $ \odot $: Element-wise multiplication


Hidden Layer Gradients (Layer $ l $):

$$
\boldsymbol{\delta}^{(l)} = \left( \boldsymbol{\delta}^{(l+1)} \mathbf{W}^{(l+1)T} \right) \odot g'(\mathbf{Z}^{(l)})
$$

This recursively computes gradients backward through the network.

### 3. **Weight Gradient Calculation**

For layer $ l $:

$$
\frac{\partial L}{\partial \mathbf{W}^{(l)}} = \mathbf{A}^{(l-1)T} \boldsymbol{\delta}^{(l)}
$$

$$
\frac{\partial L}{\partial \mathbf{b}^{(l)}} = \sum \boldsymbol{\delta}^{(l)}
$$

---

## Training: Updating Weights with Gradient Descent

### 1. **Weight Update Rule**

Weights are adjusted to minimize the loss:

$$
\mathbf{W}^{(l)} := \mathbf{W}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{W}^{(l)}}
$$

- $ \eta $: Learning rate


### 2. **Gradient Descent Variants**

- **Batch GD**: Uses full dataset for each update (slow but stable)
- **Stochastic GD (SGD)**: Updates weights per sample (fast but noisy)
- **Mini-batch GD**: Balances speed and stability using small data subsets


### 3. **Regularization Techniques**

- **Dropout**: Randomly deactivates neurons during training to prevent overfitting
- **L2 Regularization**: Adds penalty term $ \lambda \|\mathbf{W}\|^2 $ to loss

---

## Example: Training Step for a Simple Network

1. **Forward Pass**:
    - Input $ \mathbf{X} \rightarrow \mathbf{Z}^{(1)} = \mathbf{X}\mathbf{W}^{(1)} + \mathbf{b}^{(1)} $
    - Hidden activation $ \mathbf{A}^{(1)} = ReLU(\mathbf{Z}^{(1)}) $
    - Output $ \hat{\mathbf{y}} = Sigmoid(\mathbf{A}^{(1)}\mathbf{W}^{(2)} + \mathbf{b}^{(2)}) $
2. **Backward Pass**:
    - Compute $ \boldsymbol{\delta}^{(2)} = (\hat{\mathbf{y}} - \mathbf{y}) \odot \hat{\mathbf{y}} \odot (1 - \hat{\mathbf{y}}) $
    - Propagate $ \boldsymbol{\delta}^{(1)} = (\boldsymbol{\delta}^{(2)} \mathbf{W}^{(2)T}) \odot ReLU'(\mathbf{Z}^{(1)}) $
    - Calculate gradients $ \frac{\partial L}{\partial \mathbf{W}^{(2)}} = \mathbf{A}^{(1)T} \boldsymbol{\delta}^{(2)} $
3. **Weight Update**:
    - $ \mathbf{W}^{(2)} := \mathbf{W}^{(2)} - \eta \frac{\partial L}{\partial \mathbf{W}^{(2)}} $

---


## Activation Functions: Introducing Non-Linearity

Activation functions determine whether a neuron should "fire" by transforming input signals into outputs. They enable neural networks to model complex, non-linear relationships in data.

### Key Types & Uses:

1. **ReLU (Rectified Linear Unit)**
    - Formula: $ f(x) = \max(0, x) $
    - Pros: Mitigates vanishing gradients, computationally efficient.
    - Use: Default choice for hidden layers.
2. **Sigmoid**
    - Formula: $ f(x) = \frac{1}{1 + e^{-x}} $
    - Pros: Outputs probabilities (0-1).
    - Use: Binary classification output layers.
3. **Softmax**
    - Formula: $ f(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}} $
    - Pros: Outputs probability distributions.
    - Use: Multi-class classification output layers.
4. **Tanh (Hyperbolic Tangent)**
    - Formula: $ f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $
    - Pros: Zero-centered outputs (-1 to 1).
    - Use: Hidden layers in RNNs.

**Why They Matter**:
Without non-linear activation functions, neural networks collapse into linear models, incapable of learning complex patterns like images or language.

---

## Optimizers: Minimizing Loss Functions

Optimizers adjust neural network weights to reduce prediction errors. They determine how quickly and effectively a model learns.

### Common Optimizers:

**How They Work**:

- Compute gradients via backpropagation.
- Update weights using rules like:
$ \mathbf{W} := \mathbf{W} - \eta \frac{\partial L}{\partial \mathbf{W}} $ (SGD).
- Adam adds momentum and scales gradients adaptively.

**Why They Matter**:
Poor optimizer choice leads to slow convergence or unstable training. Adam is often preferred for its balance of speed and stability.

---

## Regularization: Preventing Overfitting

Regularization techniques reduce model complexity to improve generalization on unseen data.

### Key Techniques:

1. **L1/L2 Regularization**
    - L1 (Lasso): Adds $ \lambda \sum \|w\| $ to loss, promoting sparsity.
    - L2 (Ridge): Adds $ \lambda \sum w^2 $, penalizing large weights.
    - Use: Feature selection (L1), general weight control (L2).
2. **Dropout**
    - Randomly deactivates neurons during training.
    - Forces the network to learn redundant representations.
3. **Early Stopping**
    - Halts training when validation error plateaus.
    - Prevents memorization of training noise.
4. **Data Augmentation**
    - Generates synthetic training data (e.g., rotated images).
    - Exposes the model to diverse samples.

**Why They Matter**:

Overfit models excel on training data but fail on real-world inputs. Regularization balances bias and variance, ensuring robustness.

---